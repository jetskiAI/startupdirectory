name: Data Collection

on:
  schedule:
    # Run daily at midnight UTC
    - cron: "0 0 * * *"
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      source:
        description: "Data source to scrape"
        required: true
        default: "all"
        type: choice
        options:
          - yc
          - neo
          - techstars
          - all
      year:
        description: "Year to filter by (optional)"
        required: false
        type: string

jobs:
  trigger-remote-scraping:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dotenv

      - name: Run scraper trigger script
        env:
          API_BASE_URL: ${{ secrets.API_BASE_URL }}
          API_KEY: ${{ secrets.API_KEY }}
        run: |
          echo "Would trigger scraper for source: ${{ github.event.inputs.source || 'all' }}"
          echo "Year filter: ${{ github.event.inputs.year || 'none' }}"
          # This is a placeholder that will be replaced with actual script execution
          # python scripts/trigger_remote_scrape.py --source=${{ github.event.inputs.source || 'all' }}
          # Will add year parameter when script is implemented
